{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from RDFunctions import *\n",
    "# Go to each of 912 records\n",
    "# Get SI series for each record using each method\n",
    "# Then select a threshold and see sensitivity, specificity and lead time and penalized lead time for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSIseries(serial_id,dfOuranno,method,model):\n",
    "    OUTLIERSD = 2.5\n",
    "    LOWESSWINDOW = 3.0\n",
    "    record_name = dfOuranno.loc[serial_id,'RecordNum'] \n",
    "    patient_id = dfOuranno.loc[serial_id,'PatientId']\n",
    "    flname = './FinalRecords/'+str(record_name)+'n.hea'\n",
    "    recname = './FinalRecords/'+str(record_name)+'n'       \n",
    "    \n",
    "    [samples,R,S,H,firstline] = getIndexOfRRSpO2HR(flname)\n",
    "    rec =  wfdb.io.rdrecord(str(recname))\n",
    "    xrr = rec.p_signal[:,R]\n",
    "    xspo2 = rec.p_signal[:,S]\n",
    "    xhr = rec.p_signal[:,H]\n",
    "    TOTAL_LEN = len(xrr)\n",
    "    t = np.arange(0,TOTAL_LEN,1)\n",
    "    \n",
    "    [xrrnew,trrnew] = outlierRejector(xrr,t,OUTLIERSD,default=15.0)\n",
    "    [xspo2new,tspo2new] = outlierRejector(xspo2,t,OUTLIERSD, default=98.0)\n",
    "    [xhrnew,thrnew] = outlierRejector(xhr,t,OUTLIERSD)\n",
    "    \n",
    "    zrrnew = applyLowess(xrrnew,trrnew,LOWESSWINDOW*60)\n",
    "    zspo2new = applyLowess(xspo2new,tspo2new,LOWESSWINDOW*60)\n",
    "    zhrnew = applyLowess(xhrnew,thrnew,LOWESSWINDOW*60)\n",
    "    \n",
    "    tnew = zrrnew[:,0]/60.0\n",
    "    \n",
    "    rr_loess = zrrnew[:,1]\n",
    "    spo2_loess = zspo2new[:,1]\n",
    "        \n",
    "    bar_h = []\n",
    "    \n",
    "    if(method=='LR' or method=='LGB' or method=='MLP' or method=='SVM'):\n",
    "        for ii in range(24*60,TOTAL_LEN,60):\n",
    "            feature_array = getLongFeatures(rr_loess[(ii-24*60):ii],spo2_loess[(ii-24*60):ii])\n",
    "            feature_array = np.array(feature_array[0:12],dtype=np.float32)\n",
    "            predict = model.predict_proba(feature_array.reshape(1,-1))[0][1]\n",
    "            bar_h.append(predict)\n",
    "            \n",
    "    if(method=='CNN' or method=='LSTM'):\n",
    "        seg = np.zeros((1,1440,2),dtype=np.float64)\n",
    "        for ii in range(24*60,TOTAL_LEN,60):\n",
    "            seg[0,:,0] = (rr_loess[(ii-24*60):ii] - 25)/10\n",
    "            seg[0,:,1] = (spo2_loess[(ii-24*60):ii] - 93)/10\n",
    "            predict = model.predict(seg)[0,0]\n",
    "            bar_h.append(predict)\n",
    "        \n",
    "    return bar_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "annofile = r'RecordsAnno4.csv'\n",
    "dfOuranno = pd.read_csv(annofile, encoding='iso-8859-1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 \n",
      "Number of runs 92\n",
      "Total Time Seconds 8.750280\n",
      "Average Time 0.095112\n"
     ]
    }
   ],
   "source": [
    "# load logistic regression model from disk\n",
    "import time\n",
    "LR_model = pickle.load(open('logistic_model.sav', 'rb'))\n",
    "SIsequences = []\n",
    "start_time = time.time()\n",
    "for i in range(6):\n",
    "    print(i,end=\" \")\n",
    "    SIsequences.append(getSIseries(i,dfOuranno,\"LR\",LR_model))\n",
    "end_time = time.time()\n",
    "count = sum([len(e) for e in SIsequences])\n",
    "\n",
    "total_time = end_time - start_time\n",
    "print('\\nNumber of runs %d'%count)\n",
    "print('Total Time Seconds %f'%total_time)\n",
    "print('Average Time %f'%float(total_time/count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 \n",
      "Number of runs 92\n",
      "Total Time Seconds 9.796193\n",
      "Average Time 0.106480\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# load lgb model from disk\n",
    "LGB_model = pickle.load(open('lgb_model.sav', 'rb'))\n",
    "SIsequences = []\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(6):\n",
    "    print(i,end=\" \")\n",
    "    SIsequences.append(getSIseries(i,dfOuranno,\"LGB\",LGB_model))\n",
    "\n",
    "end_time = time.time()\n",
    "count = sum([len(e) for e in SIsequences])\n",
    "total_time = end_time - start_time\n",
    "print('\\nNumber of runs %d'%count)\n",
    "print('Total Time Seconds %f'%total_time)\n",
    "print('Average Time %f'%float(total_time/count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 \n",
      "Number of runs 92\n",
      "Total Time Seconds 8.706151\n",
      "Average Time 0.094632\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "MLP_model = pickle.load(open('mlp_model.sav', 'rb'))\n",
    "SIsequences = []\n",
    "start_time = time.time()\n",
    "for i in range(6):\n",
    "    print(i,end=\" \")\n",
    "    SIsequences.append(getSIseries(i,dfOuranno,\"MLP\",MLP_model))\n",
    "end_time = time.time()\n",
    "count = sum([len(e) for e in SIsequences])\n",
    "total_time = end_time - start_time\n",
    "print('\\nNumber of runs %d'%count)\n",
    "print('Total Time Seconds %f'%total_time)\n",
    "print('Average Time %f'%float(total_time/count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 \n",
      "Number of runs 92\n",
      "Total Time Seconds 8.709614\n",
      "Average Time 0.094670\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "SVM_model = pickle.load(open('svm_model.sav', 'rb'))\n",
    "SIsequences = []\n",
    "start_time = time.time()\n",
    "for i in range(6):\n",
    "    print(i,end=\" \")\n",
    "    SIsequences.append(getSIseries(i,dfOuranno,\"SVM\",SVM_model))\n",
    "end_time = time.time()\n",
    "count = sum([len(e) for e in SIsequences])\n",
    "total_time = end_time - start_time\n",
    "print('\\nNumber of runs %d'%count)\n",
    "print('Total Time Seconds %f'%total_time)\n",
    "print('Average Time %f'%float(total_time/count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 \n",
      "Number of runs 92\n",
      "Total Time Seconds 12.588340\n",
      "Average Time 0.136830\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as ks\n",
    "\n",
    "# load CNN model from disk\n",
    "CNN_model = ks.models.load_model('QuantCNN.h5')\n",
    "SIsequences = []\n",
    "start_time = time.time()\n",
    "for i in range(6):\n",
    "    print(i,end=\" \")\n",
    "    SIsequences.append(getSIseries(i,dfOuranno,\"CNN\",CNN_model))\n",
    "end_time = time.time()\n",
    "count = sum([len(e) for e in SIsequences])\n",
    "total_time = end_time - start_time\n",
    "print('\\nNumber of runs %d'%count)\n",
    "print('Total Time Seconds %f'%total_time)\n",
    "print('Average Time %f'%float(total_time/count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 \n",
      "Number of runs 92\n",
      "Total Time Seconds 32.277431\n",
      "Average Time 0.350842\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as ks\n",
    "\n",
    "# load CNN model from disk\n",
    "LSTM_model = ks.models.load_model('QuantLSTM.h5')\n",
    "SIsequences = []\n",
    "start_time = time.time()\n",
    "for i in range(6):\n",
    "    print(i,end=\" \")\n",
    "    SIsequences.append(getSIseries(i,dfOuranno,\"LSTM\",LSTM_model))\n",
    "end_time = time.time()\n",
    "count = sum([len(e) for e in SIsequences])\n",
    "total_time = end_time - start_time\n",
    "print('\\nNumber of runs %d'%count)\n",
    "print('Total Time Seconds %f'%total_time)\n",
    "print('Average Time %f'%float(total_time/count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 410.48                 Driver Version: 410.48                    |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  Quadro P5000        Off  | 00000000:02:00.0  On |                  Off |\n",
    "| 30%   44C    P8     7W / 180W |  15720MiB / 16271MiB |      1%      Default |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "                                                                               \n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                       GPU Memory |\n",
    "|  GPU       PID   Type   Process name                             Usage      |\n",
    "|=============================================================================|\n",
    "|    0      1101      G   /usr/lib/xorg/Xorg                           149MiB |\n",
    "|    0      2081      G   compiz                                       169MiB |\n",
    "|    0    127397      C   /home/ubuntu/anaconda3/bin/python          15397MiB |\n",
    "+-----------------------------------------------------------------------------+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"platform\": \"Linux\", \"platform-release\": \"4.4.0-93-generic\", \"platform-version\": \"#116-Ubuntu SMP Fri Aug 11 21:17:51 UTC 2017\", \"architecture\": \"x86_64\", \"hostname\": \"ubuntu-HP-Z440-Workstation\", \"ip-address\": \"127.0.1.1\", \"mac-address\": \"b1:aa:7a:5b:5b:47\", \"processor\": \"x86_64\", \"ram\": \"31 GB\"}'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " import platform,socket,re,uuid,json,psutil\n",
    "\n",
    "def getSystemInfo():\n",
    "    try:\n",
    "        info={}\n",
    "        info['platform']=platform.system()\n",
    "        info['platform-release']=platform.release()\n",
    "        info['platform-version']=platform.version()\n",
    "        info['architecture']=platform.machine()\n",
    "        info['hostname']=socket.gethostname()\n",
    "        info['ip-address']=socket.gethostbyname(socket.gethostname())\n",
    "        info['mac-address']=':'.join(re.findall('..', '%012x' % uuid.getnode()))\n",
    "        info['processor']=platform.processor()\n",
    "        info['ram']=str(round(psutil.virtual_memory().total / (1024.0 **3)))+\" GB\"\n",
    "        return json.dumps(info)\n",
    "    except Exception as e:\n",
    "        logging.exception(e)\n",
    "\n",
    "getSystemInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Size (in bytes) : 924\n",
      "Decision Tree Model Size (in bytes) : 67857\n",
      "Multi Layer Perceptron Model Size (in bytes) : 268831\n",
      "Support Vecotor Model Size (in bytes) : 50193\n",
      "CNN Model Size (in bytes) : 61608\n",
      "LSTM Model Size (in bytes) : 75808\n"
     ]
    }
   ],
   "source": [
    "# comparing size of models\n",
    "import os\n",
    "print(\"Logistic Regression Model Size (in bytes) : %s\"%os.stat('logistic_model.sav').st_size)\n",
    "print(\"Decision Tree Model Size (in bytes) : %s\"%os.stat('lgb_model.sav').st_size)\n",
    "print(\"Multi Layer Perceptron Model Size (in bytes) : %s\"%os.stat('mlp_model.sav').st_size)\n",
    "print(\"Support Vecotor Model Size (in bytes) : %s\"%os.stat('svm_model.sav').st_size)\n",
    "print(\"CNN Model Size (in bytes) : %s\"%os.stat('QuantCNN.h5').st_size)\n",
    "print(\"LSTM Model Size (in bytes) : %s\"%os.stat('QuantLSTM.h5').st_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
